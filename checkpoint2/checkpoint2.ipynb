{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Checkpoint:</h1>\n",
    "\n",
    "**Looking to see completetion and effort in completing the checkpoint. It's okay if it's not correct**\n",
    "\n",
    "Based off this dataset with school financial, enrollment, and achievement data, we are interested in what information is a useful indicator of student performance at the state level.\n",
    "\n",
    "This question is a bit too big for a checkpoint, however. Instead, we want you to look at smaller questions related to our overall goal. Here's the overview:\n",
    "\n",
    "1. Choose a specific test to focus on\n",
    ">Math/Reading for 4/8 grade\n",
    "* Pick or create features to use\n",
    ">Will all the features be useful in predicting test score? Are some more important than others? Should you standardize, bin, or scale the data?\n",
    "* Explore the data as it relates to that test\n",
    ">Create 2 well-labeled visualizations (graphs), each with a caption describing the graph and what it tells us about the data\n",
    "* Create training and testing data\n",
    ">Do you want to train on all the data? Only data from the last 10 years? Only Michigan data?\n",
    "* Train a ML model to predict outcome \n",
    ">Pick if you want to do a regression or classification task. For both cases, defined _exactly_ what you want to predict, and pick any model in sklearn to use (see sklearn <a href=\"https://scikit-learn.org/stable/modules/linear_model.html\">regressors</a> and <a href=\"https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\">classifiers</a>).\n",
    "* Summarize your findings\n",
    ">Write a 1 paragraph summary of what you did and make a recommendation about if and how student performance can be predicted\n",
    "\n",
    "** Include comments throughout your code! Every cleanup and preprocessing task should be documented.\n",
    "\n",
    "\n",
    "Of course, if you're finding this assignment interesting (and we really hope you do!), you are welcome to do more than the requirements! For example, you may want to see if expenditure affects 4th graders more than 8th graders. Maybe you want to look into the extended version of this dataset and see how factors like sex and race are involved. You can include all your work in this notebook when you turn it in -- just always make sure you explain what you did and interpret your results. Good luck!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Data Cleanup </h2>\n",
    "\n",
    "Import numpy, pandas, matplotlib, and seaborn\n",
    "\n",
    "(Feel free to import other libraries!)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load in the \"states_edu.csv\" dataset and take a look at the head of the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "df = pd.read_csv(\"../data/states_edu.csv\")\n",
    "array = df.values\n",
    "X = array[:,1:1715]\n",
    "Y = array[:,1:1715]\n",
    "df.head"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of              PRIMARY_KEY          STATE  YEAR  ENROLL  TOTAL_REVENUE  \\\n",
       "0           1992_ALABAMA        ALABAMA  1992     NaN      2678885.0   \n",
       "1            1992_ALASKA         ALASKA  1992     NaN      1049591.0   \n",
       "2           1992_ARIZONA        ARIZONA  1992     NaN      3258079.0   \n",
       "3          1992_ARKANSAS       ARKANSAS  1992     NaN      1711959.0   \n",
       "4        1992_CALIFORNIA     CALIFORNIA  1992     NaN     26260025.0   \n",
       "...                  ...            ...   ...     ...            ...   \n",
       "1710       2019_VIRGINIA       VIRGINIA  2019     NaN            NaN   \n",
       "1711     2019_WASHINGTON     WASHINGTON  2019     NaN            NaN   \n",
       "1712  2019_WEST_VIRGINIA  WEST_VIRGINIA  2019     NaN            NaN   \n",
       "1713      2019_WISCONSIN      WISCONSIN  2019     NaN            NaN   \n",
       "1714        2019_WYOMING        WYOMING  2019     NaN            NaN   \n",
       "\n",
       "      FEDERAL_REVENUE  STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  \\\n",
       "0            304177.0      1659028.0       715680.0          2653798.0   \n",
       "1            106780.0       720711.0       222100.0           972488.0   \n",
       "2            297888.0      1369815.0      1590376.0          3401580.0   \n",
       "3            178571.0       958785.0       574603.0          1743022.0   \n",
       "4           2072470.0     16546514.0      7641041.0         27138832.0   \n",
       "...               ...            ...            ...                ...   \n",
       "1710              NaN            NaN            NaN                NaN   \n",
       "1711              NaN            NaN            NaN                NaN   \n",
       "1712              NaN            NaN            NaN                NaN   \n",
       "1713              NaN            NaN            NaN                NaN   \n",
       "1714              NaN            NaN            NaN                NaN   \n",
       "\n",
       "      INSTRUCTION_EXPENDITURE  ...  GRADES_4_G  GRADES_8_G  GRADES_12_G  \\\n",
       "0                   1481703.0  ...     57948.0     58025.0      41167.0   \n",
       "1                    498362.0  ...      9748.0      8789.0       6714.0   \n",
       "2                   1435908.0  ...     55433.0     49081.0      37410.0   \n",
       "3                    964323.0  ...     34632.0     36011.0      27651.0   \n",
       "4                  14358922.0  ...    418418.0    363296.0     270675.0   \n",
       "...                       ...  ...         ...         ...          ...   \n",
       "1710                      NaN  ...         NaN         NaN          NaN   \n",
       "1711                      NaN  ...         NaN         NaN          NaN   \n",
       "1712                      NaN  ...         NaN         NaN          NaN   \n",
       "1713                      NaN  ...         NaN         NaN          NaN   \n",
       "1714                      NaN  ...         NaN         NaN          NaN   \n",
       "\n",
       "      GRADES_1_8_G  GRADES_9_12_G  GRADES_ALL_G  AVG_MATH_4_SCORE  \\\n",
       "0              NaN            NaN      731634.0             208.0   \n",
       "1              NaN            NaN      122487.0               NaN   \n",
       "2              NaN            NaN      673477.0             215.0   \n",
       "3              NaN            NaN      441490.0             210.0   \n",
       "4              NaN            NaN     5254844.0             208.0   \n",
       "...            ...            ...           ...               ...   \n",
       "1710           NaN            NaN           NaN             247.0   \n",
       "1711           NaN            NaN           NaN             240.0   \n",
       "1712           NaN            NaN           NaN             231.0   \n",
       "1713           NaN            NaN           NaN             242.0   \n",
       "1714           NaN            NaN           NaN             246.0   \n",
       "\n",
       "      AVG_MATH_8_SCORE  AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "0                252.0                207.0                  NaN  \n",
       "1                  NaN                  NaN                  NaN  \n",
       "2                265.0                209.0                  NaN  \n",
       "3                256.0                211.0                  NaN  \n",
       "4                261.0                202.0                  NaN  \n",
       "...                ...                  ...                  ...  \n",
       "1710             287.0                224.0                262.0  \n",
       "1711             286.0                220.0                266.0  \n",
       "1712             272.0                213.0                256.0  \n",
       "1713             289.0                220.0                267.0  \n",
       "1714             286.0                227.0                265.0  \n",
       "\n",
       "[1715 rows x 25 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should always familiarize yourself with what each column in the dataframe represents. \\ Read about the states_edu dataset here: https://www.kaggle.com/noriuk/us-education-datasets-unification-project"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use this space to rename columns, deal with missing data, etc. _(optional)_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "checkpoint2.ipynb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Exploratory Data Analysis (EDA) </h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Chosen Predictor for Test: **<Math/Reading for 4/8 grade>**   (Ex. Math for 8th grade)\n",
    "\n",
    "**(hit `Enter` to edit)**\n",
    "\n",
    "Predictor Score in the questions refers to the predictor variable you chose here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many different years of data are in our dataset? Use a pandas function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "(df['YEAR'].nunique())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's compare Michigan to Ohio. Which state has the higher average predictor score across all years?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "mi_avg = df[\"AVG_MATH_8_SCORE\"][df[\"STATE\"] == \"MICHIGAN\"].mean()\n",
    "oh_avg = df[\"AVG_MATH_8_SCORE\"][df[\"STATE\"] == \"OHIO\"].mean()\n",
    "\n",
    "if mi_avg > oh_avg:\n",
    "    print(\"Michigan\")\n",
    "elif mi_avg < oh_avg:\n",
    "    print(\"Ohio\")\n",
    "else:\n",
    "    print (\"Same Average\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ohio\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find the average for your pedictor score across all states in 2019"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "df[\"AVG_MATH_8_SCORE\"][df[\"YEAR\"] == 2019].mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "281.2641509433962"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find the maximum predictor score for every state. Hint: there's a function that allows you to do this easily"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "df.groupby(\"STATE\")[\"AVG_MATH_8_SCORE\"].max()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "STATE\n",
       "ALABAMA                 269.0\n",
       "ALASKA                  283.0\n",
       "ARIZONA                 283.0\n",
       "ARKANSAS                279.0\n",
       "CALIFORNIA              277.0\n",
       "COLORADO                292.0\n",
       "CONNECTICUT             289.0\n",
       "DELAWARE                284.0\n",
       "DISTRICT_OF_COLUMBIA    269.0\n",
       "DODEA                   293.0\n",
       "FLORIDA                 281.0\n",
       "GEORGIA                 281.0\n",
       "HAWAII                  281.0\n",
       "IDAHO                   287.0\n",
       "ILLINOIS                285.0\n",
       "INDIANA                 288.0\n",
       "IOWA                    286.0\n",
       "KANSAS                  290.0\n",
       "KENTUCKY                282.0\n",
       "LOUISIANA               273.0\n",
       "MAINE                   289.0\n",
       "MARYLAND                288.0\n",
       "MASSACHUSETTS           301.0\n",
       "MICHIGAN                280.0\n",
       "MINNESOTA               295.0\n",
       "MISSISSIPPI             274.0\n",
       "MISSOURI                286.0\n",
       "MONTANA                 293.0\n",
       "NATIONAL                285.0\n",
       "NEBRASKA                288.0\n",
       "NEVADA                  278.0\n",
       "NEW_HAMPSHIRE           296.0\n",
       "NEW_JERSEY              296.0\n",
       "NEW_MEXICO              274.0\n",
       "NEW_YORK                283.0\n",
       "NORTH_CAROLINA          286.0\n",
       "NORTH_DAKOTA            293.0\n",
       "OHIO                    290.0\n",
       "OKLAHOMA                279.0\n",
       "OREGON                  285.0\n",
       "PENNSYLVANIA            290.0\n",
       "RHODE_ISLAND            284.0\n",
       "SOUTH_CAROLINA          282.0\n",
       "SOUTH_DAKOTA            291.0\n",
       "TENNESSEE               280.0\n",
       "TEXAS                   290.0\n",
       "UTAH                    287.0\n",
       "VERMONT                 295.0\n",
       "VIRGINIA                290.0\n",
       "WASHINGTON              290.0\n",
       "WEST_VIRGINIA           274.0\n",
       "WISCONSIN               289.0\n",
       "WYOMING                 289.0\n",
       "Name: AVG_MATH_8_SCORE, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Feature Selection </h2>\n",
    "\n",
    "After exploring the data, you now have to choose features that you would use to predict the performance of the students on a chosen test (your chosen predictor). By the way, you can also create your own features. For example, perhaps you figured that maybe a state's expenditure per student may affect their overall academic performance so you create a expenditure_per_student feature.\n",
    "\n",
    "Use this space to modify or create features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (fit.support_))\n",
    "print(\"Feature Ranking: %s\" % (fit.ranking_))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 3 were given",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b2/5n7r46ps5xbb2c361x29d8680000gn/T/ipykernel_73112/2344893598.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num Features: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Selected Features: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Final feature list: **<LIST FEATURES HERE\\>**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature selection justification: **<BRIEFLY DESCRIBE WHY YOU PICKED THESE FEATURES\\>**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Visualization</h2>\n",
    "\n",
    "Use any graph you wish to see the relationship of your chosen predictor with any features you chose\n",
    "\n",
    "**Visualization 1**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**<CAPTION FOR VIZ 1>**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Visualization 2**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**<CAPTION FOR VIZ 2>**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Data Creation </h2>\n",
    "\n",
    "_Use this space to create train/test data_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = ??\n",
    "y = ??"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=??, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Prediction </h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "ML Models Resource: https://medium.com/@vijaya.beeravalli/comparison-of-machine-learning-classification-models-for-credit-card-default-data-c3cf805c9a5a"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Chosen ML task: **<REGRESSION/CLASSIFICATION>**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import your sklearn class here\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create your model here\n",
    "model = "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = model.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# FOR CLASSIFICATION ONLY:\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test,\n",
    "                         cmap=plt.cm.Blues)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# FOR REGRESSION ONLY: (pick a single column to visualize results)\n",
    "\n",
    "# Results from this graph _should not_ be used as a part of your results -- it is just here to help with intuition. \n",
    "# Instead, look at the error values and individual intercepts.\n",
    "\n",
    "\n",
    "col_name = ??\n",
    "col_index = X_train.columns.get_loc(col_name)\n",
    "\n",
    "f = plt.figure(figsize=(12,6))\n",
    "plt.scatter(X_train[col_name], y_train, color = \"red\")\n",
    "plt.scatter(X_train[col_name], model.predict(X_train), color = \"green\")\n",
    "plt.scatter(X_test[col_name], model.predict(X_test), color = \"blue\")\n",
    "\n",
    "new_x = np.linspace(X_train[col_name].min(),X_train[col_name].max(),200)\n",
    "intercept = model.predict([X_train.sort_values(col_name).iloc[0]]) - X_train[col_name].min()*model.coef_[col_index]\n",
    "plt.plot(new_x, intercept+new_x*model.coef_[col_index])\n",
    "\n",
    "plt.legend(['controlled model','true training','predicted training','predicted testing'])\n",
    "plt.xlabel(col_name)\n",
    "plt.ylabel(??)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Summary </h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**<WRITE A PARAGRAPH SUMMARIZING YOUR WORK AND FINDINGS\\>**\n",
    "\n",
    "Unfortunately I learned about this club last minute, i.e., literally today. I did not get as far as I would've liked but given my time constraints I feel that I set up the data well. Addiitonally if I was able to set up the features in a way that was conducive to parsing the data, I believe that I would be able to put together a meaningful analysis.\n",
    "\n",
    "I am not the strongest coder, but I think that with that with more practice I could make strides quickly."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "27bb5cd93b740c4a053cb3ee294840a2120d44a03583b46cdf4832f39e6bfeea"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}